{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagAndTrainingData(file):\n",
    "\t#returning tokenize sentence\n",
    "\ttags = []\n",
    "\tdocuments = []\n",
    "\tcounter = 1\n",
    "\twith open(file) as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\t#skip the first line\n",
    "\t\t\tif counter == 1:\n",
    "\t\t\t\tcounter += 1\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\ttags.append(line[:3]) #separating document_id\n",
    "\t\t\tdocuments.append(line[3:]) #separating body of the document\n",
    "\treturn tags,documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,X = tagAndTrainingData('../preprocessing/trainingdataset.txt')\n",
    "df_X = pd.Series(X,index=None)\n",
    "df_Y = pd.Series(Y,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    CARGILL UK STRIKE TALKS BREAK OFF WITHOUT RESU...\n",
       "1    UK GRAIN/POTATO FUTURES VOLUME DOWN IN FEBRUAR...\n",
       "2    EUROPEAN SOY/FEED MARKET OPENS QUIETLY ROTTERD...\n",
       "3    DUTCH SOYMEAL IMPORTS FALL IN JANUARY HEERLEN,...\n",
       "4    FALLING SOYBEAN CRUSH RATIOS CUT OUTPUT AUTHOR...\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for extracting keyword we going to use RAKE algorithm\n",
    "#run rake algorithm for each document and extract the important terms from the document\n",
    "from rake_nltk import Rake\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_the_document(stopwords,document):\n",
    "    word_tokens = word_tokenize(document)\n",
    "    filtered_sentence = [word for word in word_tokens if not word in stopwords] #return as list\n",
    "    #join the document without the stopwords\n",
    "    filtered_document = ' '.join(filtered_sentence)\n",
    "    return filtered_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from Rake Algorithm is as a List.so we have to join the extracted keyword for each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Extracting Keywords from 1000 documents\n",
      "Finished Extracting Keywords from 2000 documents\n",
      "Finished Extracting Keywords from 3000 documents\n",
      "Finished Extracting Keywords from 4000 documents\n",
      "Finished Extracting Keywords from 5000 documents\n",
      "Finished Extracting Keywords from 6000 documents\n",
      "Finished Extracting Keywords from 7000 documents\n",
      "Finished Extracting Keywords from 8000 documents\n",
      "Finished Extracting Keywords from 9000 documents\n",
      "Finished Extracting Keywords from 10000 documents\n",
      "Finished Extracting Keywords from 11000 documents\n"
     ]
    }
   ],
   "source": [
    "#before extracting keywords from the document we want to preprocess the dataset\n",
    "r = Rake() #create object for Rake\n",
    "keywords_list = []\n",
    "stopset = nltk.corpus.stopwords.words('english')\n",
    "i=1\n",
    "for documents in df_X:\n",
    "    preprocessed_docs = preprocess_the_document(stopset,documents)#preprocessed document\n",
    "    r.extract_keywords_from_text(preprocessed_docs)\n",
    "    ranked_phrase = r.get_ranked_phrases() #type as a list\n",
    "    #join the list\n",
    "    join_ranked_phrase_docs = \" \".join(ranked_phrase)\n",
    "    keywords_list.append(join_ranked_phrase_docs)\n",
    "    if i%1000 == 0:\n",
    "        print(\"Finished Extracting Keywords from {} documents\".format(i))\n",
    "    i+=1 #increment the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11475"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"march traded volumes uk grain potato futures february previous month pigmeat pig cash settlement futures higher value declined nine mln stg mln nine pigmeat contracts traded february tonnes registered main crop potato futures february valued mln stg stg pig cash settlement futures saw contracts traded official figures show combined wheat barley futures trade declined mln stg january soymeal futures trade totalled value fell mln stg mln potato futures volume six previous month grain feed trade association uk grain tonnes mln january february london figures show stg '' value rose stg valued tonnes representing carcases january versus total gafta\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = []\n",
    "for docs in df_Y:\n",
    "    document_id.append(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11475"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save in a file for future reference\n",
    "len(document_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create as a dataFrame\n",
    "df = pd.DataFrame({'Document_id':document_id,'Keywords':keywords_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as txt file\n",
    "df.to_csv('features_2.txt',sep=\",\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
