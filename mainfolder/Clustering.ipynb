{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially we need document folders and document id's\n",
    "path_to_dataset = '/home/madhi/Documents/python programs/neuralnetworks/fp/Reuters21578-Apte-115Cat/training'\n",
    "folder_list = os.listdir(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('palladium', ['0001792', '0001862'])\n"
     ]
    }
   ],
   "source": [
    "#make a dictionary of document category and documents contain in the folder\n",
    "cat_and_docs = [] #list\n",
    "document_folder = [] #list\n",
    "for docs_folder in folder_list:\n",
    "    folder_path = path_to_dataset + \"/\" + docs_folder\n",
    "    list_of_documents = os.listdir(folder_path)\n",
    "    for real_docs in list_of_documents:\n",
    "        document_folder.append(real_docs)\n",
    "    #append folder_name and docs into the same list\n",
    "    cat_and_docs.append((docs_folder,document_folder))\n",
    "    #empty the document_folder list\n",
    "    document_folder = []\n",
    "    \n",
    "print(cat_and_docs[1]) #the list is in format category and number of docs in that list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make into dictionary\n",
    "cate = [] \n",
    "documents = []\n",
    "\n",
    "for category,docs in cat_and_docs:\n",
    "    cate.append(category)\n",
    "    documents.append(docs)\n",
    "    \n",
    "#convert into dictionary\n",
    "total_dataset = dict(zip(cate,documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>alfonsin,allsuite,arnott,bonded,briefed,bulax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dependent,cellulosa,allentown,bases,ergenc,err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cellulosa,emphasizing,edina,celsius,dependent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>edina,cellulosa,allentown,emphasizing,celsius,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>downed,ecologists,edina,emphasizing,cellulosa,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                           features\n",
       "0       0  alfonsin,allsuite,arnott,bonded,briefed,bulax,...\n",
       "1       0  dependent,cellulosa,allentown,bases,ergenc,err...\n",
       "2       0  cellulosa,emphasizing,edina,celsius,dependent,...\n",
       "3       0  edina,cellulosa,allentown,emphasizing,celsius,...\n",
       "4       0  downed,ecologists,edina,emphasizing,cellulosa,..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.read_csv('features.txt',sep='\\t',header=None,names=['doc_id','features'])\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11475,) (11475,)\n"
     ]
    }
   ],
   "source": [
    "doc_category = feature_df['doc_id']\n",
    "features = feature_df['features']\n",
    "#convert into pandas Series\n",
    "features_id = pd.Series(doc_category)\n",
    "features_series = pd.Series(features)\n",
    "\n",
    "print(features_id.shape,features_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11475 11475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#in features_series list all features is considered as a single string\n",
    "#we need to sepearate the words and have to apply tf-idf vectorizer and ngram to each words\n",
    "def document_category(features_id):\n",
    "    docs_category = []\n",
    "    for ids in features_id:\n",
    "        docs_category.append(ids)\n",
    "    return docs_category\n",
    "\n",
    "def separate_features_the_series(feature_series):\n",
    "    main_feature_series = []\n",
    "    for features in feature_series:\n",
    "        data_features = features.replace(\",\",\" \")\n",
    "        main_feature_series.append(data_features)\n",
    "    return main_feature_series\n",
    "\n",
    "docs_id = document_category(features_id)\n",
    "features_splitted = separate_features_the_series(features_series)\n",
    "print(len(docs_id),len(features_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 660 ms, sys: 4 ms, total: 664 ms\n",
      "Wall time: 802 ms\n",
      "(11475, 14240)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0,max_features=20000,use_idf=True,ngram_range=(1,3))\n",
    "%time  tfidf_matrix = tfidf_vectorizer.fit_transform(features_splitted)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11475x14240 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 309825 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dist = 1-cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.88178420e-16,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00, -6.66133815e-16,  9.30546629e-01, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  9.30546629e-01,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -8.88178420e-16,  9.72391357e-01,  9.75894543e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         9.72391357e-01,  1.11022302e-16,  9.64164476e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         9.75894543e-01,  9.64164476e-01,  8.88178420e-16]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.56 s, sys: 96 ms, total: 8.66 s\n",
      "Wall time: 8.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters = num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "#dump the clusters for later user\n",
    "#joblib.dump(km,'clusters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "#load the cluster\n",
    "cl_load = joblib.load('clusters.pkl')\n",
    "def_clusters = cl_load.labels_.tolist()\n",
    "print(def_clusters[:96]) #just print to see the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert features_splitted into a Series Pandas\n",
    "document = {'category':docs_id,'content':features_splitted ,'clusters':def_clusters}\n",
    "frame = pd.DataFrame(document,index=[def_clusters],columns=['category','content','clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7605\n",
       "3    1290\n",
       "2    1035\n",
       "4     960\n",
       "0     585\n",
       "Name: clusters, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>dynalectron athletic elections bhputah denwa c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>detected conservatism bonn decided converts da...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>coopervision clercq chatted enfield employee e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl dwindled educate danger academics amnount ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>athletic alatenn cry counties arbitrary compac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>clercq discuss abating august completion brant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>athletic bale cole darman audit applications b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>ameritrust clipbecause airframe dnzr column be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl breathing ecuadoreans culver dur clock cru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl csx bni awaits creditcard coop creates dec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            content  clusters\n",
       "1        87  dynalectron athletic elections bhputah denwa c...         1\n",
       "3        87  detected conservatism bonn decided converts da...         3\n",
       "1        87  coopervision clercq chatted enfield employee e...         1\n",
       "1        87  cbl dwindled educate danger academics amnount ...         1\n",
       "3        87  athletic alatenn cry counties arbitrary compac...         3\n",
       "1        87  clercq discuss abating august completion brant...         1\n",
       "3        87  athletic bale cole darman audit applications b...         3\n",
       "1        87  ameritrust clipbecause airframe dnzr column be...         1\n",
       "1        87  cbl breathing ecuadoreans culver dur clock cru...         1\n",
       "1        87  cbl csx bni awaits creditcard coop creates dec...         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.iloc[9658:9668] #the less number of clusters the more number of same category documents belongs to same clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "0    51.921368\n",
       "1    48.746614\n",
       "2    47.077295\n",
       "3    48.712403\n",
       "4    48.685417\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = frame['category'].groupby(frame['clusters'])\n",
    "grouped.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster 2 have lowest rank which indicates the document is being pretty good classified\n",
    "cluster 1,3,4 are approximately equal to each other , document classified is average\n",
    "cluster 0 have highest rank which some documents are unnecessary classified into that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop(['document_id','documents'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11476\n"
     ]
    }
   ],
   "source": [
    "#convert document into series\n",
    "series_docs = pd.Series(documents)\n",
    "individual_docs = [] #to store individual documents\n",
    "for document in series_docs:\n",
    "    for indi_docs in document:\n",
    "        individual_docs.append(indi_docs)\n",
    "print(len(individual_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11475,)\n"
     ]
    }
   ],
   "source": [
    "series_indi_docs = pd.Series(individual_docs)\n",
    "series_indi_docs = series_indi_docs[:-1]\n",
    "print(series_indi_docs.shape) #the shape of frame is (11475,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>clusters</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>alfonsin allsuite arnott bonded briefed bulax ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dependent cellulosa allentown bases ergenc err...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cellulosa emphasizing edina celsius dependent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>edina cellulosa allentown emphasizing celsius ...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>downed ecologists edina emphasizing cellulosa ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            content  clusters  \\\n",
       "1         0  alfonsin allsuite arnott bonded briefed bulax ...         1   \n",
       "1         0  dependent cellulosa allentown bases ergenc err...         1   \n",
       "1         0  cellulosa emphasizing edina celsius dependent ...         1   \n",
       "2         0  edina cellulosa allentown emphasizing celsius ...         2   \n",
       "1         0  downed ecologists edina emphasizing cellulosa ...         1   \n",
       "\n",
       "  document  \n",
       "1      NaN  \n",
       "1      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "1      NaN  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['document'] = series_indi_docs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>clusters</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>aaa abates abdelrahim abdulaziz abf ability aa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0005167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>ababa aaminus aare abdul aar abdulaziz aarnoud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0004782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>aaa abdul abattoirs aas aaplus abnnas abandonm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0005167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>aaarated aaix abandon abbreviated abandoning a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0004556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>abf aachener abha aaminus abdulrahim abev abso...</td>\n",
       "      <td>1</td>\n",
       "      <td>0001973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            content  clusters  \\\n",
       "0       113  aaa abates abdelrahim abdulaziz abf ability aa...         0   \n",
       "0       114  ababa aaminus aare abdul aar abdulaziz aarnoud...         0   \n",
       "0       114  aaa abdul abattoirs aas aaplus abnnas abandonm...         0   \n",
       "0       115  aaarated aaix abandon abbreviated abandoning a...         0   \n",
       "1       115  abf aachener abha aaminus abdulrahim abev abso...         1   \n",
       "\n",
       "  document  \n",
       "0  0005167  \n",
       "0  0004782  \n",
       "0  0005167  \n",
       "0  0004556  \n",
       "1  0001973  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114750\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "#print(len(terms))  14,240 terms\n",
    "important_terms = [] #to store important terms\n",
    "important_terms_stemmed = [] #to store important terms stemmed\n",
    "for terms in features_series:\n",
    "    #replace the comma by space for word sepearation\n",
    "    data = terms.replace(\",\",\" \")\n",
    "    words_splitted = data.split()\n",
    "    for words in words_splitted:\n",
    "        important_terms.append(words)\n",
    "print(len(important_terms))\n",
    "vocab_frame = pd.DataFrame({'words': important_terms})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
