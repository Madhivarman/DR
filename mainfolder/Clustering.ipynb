{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially we need document folders and document id's\n",
    "path_to_dataset = '/home/madhi/Documents/python programs/neuralnetworks/fp/Reuters21578-Apte-115Cat/training'\n",
    "folder_list = os.listdir(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of document category and documents contain in the folder\n",
    "cat_and_docs = [] #list\n",
    "document_folder = [] #list\n",
    "for docs_folder in folder_list:\n",
    "    folder_path = path_to_dataset + \"/\" + docs_folder\n",
    "    list_of_documents = os.listdir(folder_path)\n",
    "    for real_docs in list_of_documents:\n",
    "        document_folder.append(real_docs)\n",
    "    #append folder_name and docs into the same list\n",
    "    cat_and_docs.append((docs_folder,document_folder))\n",
    "    #empty the document_folder list\n",
    "    document_folder = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make into dictionary\n",
    "cate = [] \n",
    "documents = []\n",
    "\n",
    "for category,docs in cat_and_docs:\n",
    "    cate.append(category)\n",
    "    documents.append(docs)\n",
    "    \n",
    "#convert into dictionary\n",
    "total_dataset = dict(zip(cate,documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>alfonsin,allsuite,arnott,bonded,briefed,bulax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dependent,cellulosa,allentown,bases,ergenc,err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cellulosa,emphasizing,edina,celsius,dependent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>edina,cellulosa,allentown,emphasizing,celsius,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>downed,ecologists,edina,emphasizing,cellulosa,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                           features\n",
       "0       0  alfonsin,allsuite,arnott,bonded,briefed,bulax,...\n",
       "1       0  dependent,cellulosa,allentown,bases,ergenc,err...\n",
       "2       0  cellulosa,emphasizing,edina,celsius,dependent,...\n",
       "3       0  edina,cellulosa,allentown,emphasizing,celsius,...\n",
       "4       0  downed,ecologists,edina,emphasizing,cellulosa,..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.read_csv('features.txt',sep='\\t',header=None,names=['doc_id','features'])\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11475,) (11475,)\n"
     ]
    }
   ],
   "source": [
    "doc_category = feature_df['doc_id']\n",
    "features = feature_df['features']\n",
    "#convert into pandas Series\n",
    "features_id = pd.Series(doc_category)\n",
    "features_series = pd.Series(features)\n",
    "\n",
    "print(features_id.shape,features_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11475 11475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#in features_series list all features is considered as a single string\n",
    "#we need to sepearate the words and have to apply tf-idf vectorizer and ngram to each words\n",
    "def document_category(features_id):\n",
    "    docs_category = []\n",
    "    for ids in features_id:\n",
    "        docs_category.append(ids)\n",
    "    return docs_category\n",
    "\n",
    "def separate_features_the_series(feature_series):\n",
    "    main_feature_series = []\n",
    "    for features in feature_series:\n",
    "        data_features = features.replace(\",\",\" \")\n",
    "        main_feature_series.append(data_features)\n",
    "    return main_feature_series\n",
    "\n",
    "docs_id = document_category(features_id)\n",
    "features_splitted = separate_features_the_series(features_series)\n",
    "print(len(docs_id),len(features_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 656 ms, sys: 0 ns, total: 656 ms\n",
      "Wall time: 653 ms\n",
      "(11475, 14240)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0,max_features=20000,use_idf=True,ngram_range=(1,3))\n",
    "%time  tfidf_matrix = tfidf_vectorizer.fit_transform(features_splitted)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11475x14240 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 309825 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dist = 1-cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.88178420e-16,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00, -6.66133815e-16,  9.30546629e-01, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  9.30546629e-01,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -8.88178420e-16,  9.72391357e-01,  9.75894543e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         9.72391357e-01,  1.11022302e-16,  9.64164476e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         9.75894543e-01,  9.64164476e-01,  8.88178420e-16]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.61 s, sys: 12 ms, total: 7.62 s\n",
      "Wall time: 7.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clusters.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters = num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "#dump the clusters for later user\n",
    "joblib.dump(km,'clusters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "#load the cluster\n",
    "cl_load = joblib.load('clusters.pkl')\n",
    "def_clusters = cl_load.labels_.tolist()\n",
    "print(def_clusters[:96]) #just print to see the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert features_splitted into a Series Pandas\n",
    "document = {'category':docs_id,'content':features_splitted ,'clusters':def_clusters}\n",
    "frame = pd.DataFrame(document,index=[def_clusters],columns=['category','content','clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7605\n",
       "3    1290\n",
       "2    1035\n",
       "4     960\n",
       "0     585\n",
       "Name: clusters, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>dynalectron athletic elections bhputah denwa c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>detected conservatism bonn decided converts da...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>coopervision clercq chatted enfield employee e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl dwindled educate danger academics amnount ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>athletic alatenn cry counties arbitrary compac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>clercq discuss abating august completion brant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>athletic bale cole darman audit applications b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>ameritrust clipbecause airframe dnzr column be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl breathing ecuadoreans culver dur clock cru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>cbl csx bni awaits creditcard coop creates dec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            content  clusters\n",
       "1        87  dynalectron athletic elections bhputah denwa c...         1\n",
       "3        87  detected conservatism bonn decided converts da...         3\n",
       "1        87  coopervision clercq chatted enfield employee e...         1\n",
       "1        87  cbl dwindled educate danger academics amnount ...         1\n",
       "3        87  athletic alatenn cry counties arbitrary compac...         3\n",
       "1        87  clercq discuss abating august completion brant...         1\n",
       "3        87  athletic bale cole darman audit applications b...         3\n",
       "1        87  ameritrust clipbecause airframe dnzr column be...         1\n",
       "1        87  cbl breathing ecuadoreans culver dur clock cru...         1\n",
       "1        87  cbl csx bni awaits creditcard coop creates dec...         1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.iloc[9658:9668] #the less number of clusters the more number of same category documents belongs to same clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "0    51.921368\n",
       "1    48.746614\n",
       "2    47.077295\n",
       "3    48.712403\n",
       "4    48.685417\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = frame['category'].groupby(frame['clusters'])\n",
    "grouped.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster 2 have lowest rank which indicates the document is being pretty good classified\n",
    "cluster 1,3,4 are approximately equal to each other , document classified is average\n",
    "cluster 0 have highest rank which some documents are unnecessary classified into that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
